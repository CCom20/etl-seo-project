{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from cleantext import clean\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "main_url = 'https://www.ccu.edu/undergrad/'\n",
    "\n",
    "browser.visit(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_soup = bs(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_urls = program_soup.select('li a.uk-panel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage_info = []\n",
    "\n",
    "for u in program_urls:\n",
    "    page_dict = {}\n",
    "    program_link = u.get('href')\n",
    "    program_url_full = f'https://www.ccu.edu/undergrad/{program_link}'\n",
    "    browser.visit(program_url_full)\n",
    "    page_html = browser.html\n",
    "    page_soup = bs(page_html, 'html.parser')\n",
    "    page_title = page_soup.find('title').text\n",
    "    page_h1 = page_soup.find('h1').text\n",
    "    page_paras = page_soup.select('div.expandable--content')\n",
    "    page_text = []\n",
    "    for p in page_paras:\n",
    "        page_text.append(p.text)\n",
    "        clean_paras = clean(page_text, no_punct=True)\n",
    "        tokens = [t for t in clean_paras.split()]\n",
    "        clean_tokens = tokens[:]\n",
    "        for token in tokens:\n",
    "            if token in stopwords.words('english'):\n",
    "                clean_tokens.remove(token)\n",
    "        freq = nltk.FreqDist(clean_tokens)\n",
    "        freq_words = []\n",
    "        for key,val in freq.most_common(10):\n",
    "            words_dict = {}\n",
    "            words_dict[\"word\"] = key\n",
    "            words_dict[\"count\"] = val\n",
    "            freq_words.append(words_dict) \n",
    "    print(freq_words)\n",
    "    \n",
    "#     page_dict['page_title'] = page_title\n",
    "#     page_dict['page_h1'] = page_h1\n",
    "#     page_dict['page_paras'] = \n",
    "\n",
    "#     webpage_info.append(page_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = []\n",
    "for key,val in freq.most_common(10):\n",
    "    words_dict = {}\n",
    "    words_dict[\"word\"] = key\n",
    "    words_dict[\"count\"] = val\n",
    "    freq_words.append(words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = tokens[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokens:\n",
    "    if token in stopwords.words('english'):\n",
    "        clean_tokens.remove(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in page_text:\n",
    "    clean(page_text, no_punct=True)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_info[\"page_title\"] = page_title\n",
    "page_info[\"page_h1\"] = page_h1\n",
    "page_info[\"page_text\"] = page_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text = clean(p.text, no_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for t in p_text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text = []\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_page_text = []\n",
    "\n",
    "for p in page_text:\n",
    "    p_text = clean(p.text, no_punct=True)\n",
    "    tokens = [t for t in p_text.split()]\n",
    "    clean_page_text.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
